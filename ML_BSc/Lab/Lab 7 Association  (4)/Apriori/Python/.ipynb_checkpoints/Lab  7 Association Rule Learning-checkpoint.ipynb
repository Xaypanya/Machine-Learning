{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbbf481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install plotly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f217c352",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7324/1891636013.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori,association_rules\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "#https://www.kaggle.com/code/evrenermis/association-rule-based-learning-explained/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Data Load\n",
    "data = pd.read_csv(\"Market_Basket_Optimisation.csv\", header=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80ea095",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add0db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c25831",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a09978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Data Visualizations\n",
    "# 1. Gather All Items of Each Transactions into Numpy Array\n",
    "transaction = []\n",
    "for i in range(0, data.shape[0]):\n",
    "    for j in range(0, data.shape[1]):\n",
    "        transaction.append(data.values[i,j])\n",
    "\n",
    "transaction = np.array(transaction)\n",
    "\n",
    "# 2. Transform Them a Pandas DataFrame\n",
    "df = pd.DataFrame(transaction, columns=[\"items\"]) \n",
    "df[\"incident_count\"] = 1 # Put 1 to Each Item For Making Countable Table, to be able to perform Group By\n",
    "\n",
    "# 3. Delete NaN Items from Dataset\n",
    "indexNames = df[df['items'] == \"nan\" ].index\n",
    "df.drop(indexNames , inplace=True)\n",
    "\n",
    "# 4. Final Step: Make a New Appropriate Pandas DataFrame for Visualizations  \n",
    "df_table = df.groupby(\"items\").sum().sort_values(\"incident_count\", ascending=False).reset_index()\n",
    "\n",
    "# 5. Initial Visualizations\n",
    "df_table.head(10).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10854374",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table[\"all\"] = \"all\" # to have a same origin\n",
    "\n",
    "fig = px.treemap(df_table.head(30), path=['all', \"items\"], values='incident_count',\n",
    "                  color=df_table[\"incident_count\"].head(30), hover_data=['items'],\n",
    "                  color_continuous_scale='Blues',\n",
    "                  )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0afc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Every Transaction to Seperate List & Gather Them into Numpy Array\n",
    "# By Doing So, We Will Be Able To Iterate Through Array of Transactions\n",
    "\n",
    "transaction = []\n",
    "for i in range(data.shape[0]):\n",
    "    transaction.append([str(data.values[i,j]) for j in range(data.shape[1])])\n",
    "    \n",
    "transaction = np.array(transaction)\n",
    "\n",
    "# Create a DataFrame In Order To Check Status of Top20 Items\n",
    "\n",
    "top20 = df_table[\"items\"].head(20).values\n",
    "array = []\n",
    "df_top20_multiple_record_check = pd.DataFrame(columns=top20)\n",
    "\n",
    "for i in range(0, len(top20)):\n",
    "    array = []\n",
    "    for j in range(0,transaction.shape[0]):\n",
    "        array.append(np.count_nonzero(transaction[j]==top20[i]))\n",
    "        if len(array) == len(data):\n",
    "            df_top20_multiple_record_check[top20[i]] = array\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "\n",
    "df_top20_multiple_record_check.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c2fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top20_multiple_record_check.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0616bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top20_multiple_record_check.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb3a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Gather Only First Choice of Each Transactions into Numpy Array\n",
    "# Similar Pattern to Above, Only Change is the Column Number \"0\" in Append Function\n",
    "transaction = []\n",
    "for i in range(0, data.shape[0]):\n",
    "    transaction.append(data.values[i,0])\n",
    "\n",
    "transaction = np.array(transaction)\n",
    "\n",
    "# 2. Transform Them a Pandas DataFrame\n",
    "df_first = pd.DataFrame(transaction, columns=[\"items\"])\n",
    "df_first[\"incident_count\"] = 1\n",
    "\n",
    "# 3. Delete NaN Items from Dataset\n",
    "indexNames = df_first[df_first['items'] == \"nan\" ].index\n",
    "df_first.drop(indexNames , inplace=True)\n",
    "\n",
    "# 4. Final Step: Make a New Appropriate Pandas DataFrame for Visualizations  \n",
    "df_table_first = df_first.groupby(\"items\").sum().sort_values(\"incident_count\", ascending=False).reset_index()\n",
    "df_table_first[\"food\"] = \"food\"\n",
    "df_table_first = df_table_first.truncate(before=-1, after=15) # Fist 15 Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "first_choice = nx.from_pandas_edgelist(df_table_first, source = 'food', target = \"items\", edge_attr = True)\n",
    "pos = nx.spring_layout(first_choice)\n",
    "nx.draw_networkx_nodes(first_choice, pos, node_size = 12500, node_color = \"lavender\")\n",
    "nx.draw_networkx_edges(first_choice, pos, width = 3, alpha = 0.6, edge_color = 'black')\n",
    "nx.draw_networkx_labels(first_choice, pos, font_size = 18, font_family = 'sans-serif')\n",
    "plt.axis('off')\n",
    "plt.grid()\n",
    "plt.title('Top 15 First Choices', fontsize = 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95335669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Gather Only Second Choice of Each Transaction into Numpy Array\n",
    "\n",
    "transaction = []\n",
    "for i in range(0, data.shape[0]):\n",
    "    transaction.append(data.values[i,1])\n",
    "\n",
    "transaction = np.array(transaction)\n",
    "\n",
    "# 2. Transform Them a Pandas DataFrame\n",
    "df_second = pd.DataFrame(transaction, columns=[\"items\"]) \n",
    "df_second[\"incident_count\"] = 1\n",
    "\n",
    "# 3. Delete NaN Items from Dataset\n",
    "indexNames = df_second[df_second['items'] == \"nan\" ].index\n",
    "df_second.drop(indexNames , inplace=True)\n",
    "\n",
    "# 4. Final Step: Make a New Appropriate Pandas DataFrame for Visualizations  \n",
    "df_table_second = df_second.groupby(\"items\").sum().sort_values(\"incident_count\", ascending=False).reset_index()\n",
    "df_table_second[\"food\"] = \"food\"\n",
    "df_table_second = df_table_second.truncate(before=-1, after=15) # Fist 15 Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1a0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "second_choice = nx.from_pandas_edgelist(df_table_second, source = 'food', target = \"items\", edge_attr = True)\n",
    "pos = nx.spring_layout(second_choice)\n",
    "nx.draw_networkx_nodes(second_choice, pos, node_size = 12500, node_color = \"honeydew\")\n",
    "nx.draw_networkx_edges(second_choice, pos, width = 3, alpha = 0.6, edge_color = 'black')\n",
    "nx.draw_networkx_labels(second_choice, pos, font_size = 18, font_family = 'sans-serif')\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "plt.axis('off')\n",
    "plt.grid()\n",
    "plt.title('Top 15 Second Choices', fontsize = 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e80db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Gather Only Third Choice of Each Transaction into Numpy Array\n",
    "## For Column \"2\"\n",
    "transaction = []\n",
    "for i in range(0, data.shape[0]):\n",
    "    transaction.append(data.values[i,2])\n",
    "\n",
    "transaction = np.array(transaction)\n",
    "\n",
    "# 2. Transform Them a Pandas DataFrame\n",
    "df_third = pd.DataFrame(transaction, columns=[\"items\"]) # Transaction Item Name\n",
    "df_third[\"incident_count\"] = 1 # Put 1 to Each Item For Making Countable Table, Group By Will Be Done Later On\n",
    "\n",
    "# 3. Delete NaN Items from Dataset\n",
    "indexNames = df_third[df_third['items'] == \"nan\" ].index\n",
    "df_third.drop(indexNames , inplace=True)\n",
    "\n",
    "# 4. Final Step: Make a New Appropriate Pandas DataFrame for Visualizations  \n",
    "df_table_third = df_third.groupby(\"items\").sum().sort_values(\"incident_count\", ascending=False).reset_index()\n",
    "df_table_third[\"food\"] = \"food\"\n",
    "df_table_third = df_table_third.truncate(before=-1, after=15) # Fist 15 Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63377144",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Bar(x=df_table_third[\"items\"], y=df_table_third[\"incident_count\"],\n",
    "            hovertext=df_table_third[\"items\"], text=df_table_third[\"incident_count\"], textposition=\"outside\")])\n",
    "\n",
    "fig.update_traces(marker_color='rgb(158,202,225)', marker_line_color='rgb(8,48,107)',\n",
    "                  marker_line_width=1.5, opacity=0.65)\n",
    "fig.update_layout(title_text=\"Customers' Third Choices\", template=\"plotly_dark\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f694f3e",
   "metadata": {},
   "source": [
    "# 4.  Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c105c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Every Transaction to Seperate List & Gather Them into Numpy Array\n",
    "\n",
    "transaction = []\n",
    "for i in range(data.shape[0]):\n",
    "    transaction.append([str(data.values[i,j]) for j in range(data.shape[1])])\n",
    "    \n",
    "transaction = np.array(transaction)\n",
    "transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transaction).transform(transaction)\n",
    "dataset = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0cd36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeddb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "first50 = df_table[\"items\"].head(50).values # Select Top50\n",
    "dataset = dataset.loc[:,first50] # Extract Top50\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afba009",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d792e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns\n",
    "# We extracted first 50 column successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd7e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset into 1-0 encoding\n",
    "\n",
    "def encode_units(x):\n",
    "    if x == False:\n",
    "        return 0 \n",
    "    if x == True:\n",
    "        return 1\n",
    "    \n",
    "dataset = dataset.applymap(encode_units)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfbd210",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b352d4bd",
   "metadata": {},
   "source": [
    "# 5. Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5da09",
   "metadata": {},
   "source": [
    "Main Concepts of Association Rules / Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e1e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the most frequest itemsets via Mlxtend.\n",
    "# The length column has been added to increase ease of filtering.\n",
    "\n",
    "frequent_itemsets = apriori(dataset, min_support=0.01, use_colnames=True)\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64770156",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets[ (frequent_itemsets['length'] == 2) &\n",
    "                   (frequent_itemsets['support'] >= 0.05) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bc462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets[ (frequent_itemsets['length'] == 3) ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b571100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create our rules by defining metric and its threshold.\n",
    "\n",
    "# For a start, \n",
    "#      We set our metric as \"Lift\" to define whether antecedents & consequents are dependent our not.\n",
    "#      Treshold is selected as \"1.2\" since it is required to have lift scores above than 1 if there is dependency.\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.2)\n",
    "rules[\"antecedents_length\"] = rules[\"antecedents\"].apply(lambda x: len(x))\n",
    "rules[\"consequents_length\"] = rules[\"consequents\"].apply(lambda x: len(x))\n",
    "rules.sort_values(\"lift\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ed89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values based on confidence\n",
    "\n",
    "rules.sort_values(\"confidence\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[~rules[\"consequents\"].str.contains(\"mineral water\", regex=False) & \n",
    "      ~rules[\"antecedents\"].str.contains(\"mineral water\", regex=False)].sort_values(\"confidence\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84562158",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[rules[\"antecedents\"].str.contains(\"ground beef\", regex=False) & rules[\"antecedents_length\"] == 1].sort_values(\"confidence\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee957727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
